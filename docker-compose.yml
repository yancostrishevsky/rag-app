---
version: '3.9'

services:
  llm-generator:
    build:
      context: services/llm-generator/
      dockerfile: llm-generator.Dockerfile
      args:
        - gpus=all
    container_name: llm-generator
    ports:
      - 11434:11434
    volumes:
      - ./persist_dir/llm-generator:/root/.ollama
    networks:
      - rag-net
    environment:
      - LLM_GENERATOR_MODEL=llama3.2:1b
    

networks:
  rag-net:
    driver: bridge
