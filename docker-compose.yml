---
version: '3.9'

services:
  main-llm-responder:
    build:
      context: services/llm-endpoint/
      dockerfile: llm-endpoint.Dockerfile

    container_name: main-llm-responder
    ports:
      - 11434:11434
    volumes:
      - ./persist_dir/main-llm-responder:/root/.ollama
    networks:
      - rag-net
    environment:
      - LLM_GENERATOR_MODEL=llama3.1:8b
      - OLLAMA_DEBUG=2
      - OLLAMA_HOST=0.0.0.0:11434

  guard-llm:
    build:
      context: services/llm-endpoint/
      dockerfile: llm-endpoint.Dockerfile

    container_name: guard-llm
    ports:
      - 11435:11435
    volumes:
      - ./persist_dir/guard-llm:/root/.ollama
    networks:
      - rag-net
    environment:
      - LLM_GENERATOR_MODEL=llama-guard3:1b
      - OLLAMA_DEBUG=2
      - OLLAMA_HOST=0.0.0.0:11435
    

networks:
  rag-net:
    driver: bridge
