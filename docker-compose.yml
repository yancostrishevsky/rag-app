---
version: '3.9'

services:
  llm-generator:
    build:
      context: services/llm-generator/
      dockerfile: llm-generator.Dockerfile

    container_name: llm-generator
    ports:
      - 11434:11434
    volumes:
      - ./persist_dir/llm-generator:/root/.ollama
    networks:
      - rag-net
    environment:
      - LLM_GENERATOR_MODEL=llama3.1:8b
      - OLLAMA_DEBUG=2
      - OLLAMA_HOST=0.0.0.0:11434
    

networks:
  rag-net:
    driver: bridge
