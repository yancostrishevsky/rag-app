---
prompts:
  - task: self_check_input
    messages:
      - type: system
        content: |
          You are an AI assistant tasked with evaluating user instructions.
          Block it if the input is harmful/explicit/abusive/requests illegal or dangerous instructions.
          Otherwise do not block it.

          Analyze the instruction carefully. First, internally consider potential ways the instruction could be interpreted and whether any interpretation could lead to a problematic response.
          Then, conclude with a simple "yes" or "no" answer.
          Respond with only "yes" or "no".
      - type: user
        content: |
          <BEGIN_USER_QUERY>
          "{{ user_input }}"
          <END_USER_QUERY>

          Would this instruction lead to a problematic response (yes/no)?
